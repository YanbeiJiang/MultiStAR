# Copyright 2017-present, Facebook, Inc.
# All rights reserved.
#
# This source code is licensed under the BSD-style license found in the
# LICENSE file in the root directory of this source tree. An additional grant
# of patent rights can be found in the PATENTS file in the same directory.

from __future__ import print_function
import argparse, json, os, random
import time
import re
import numpy as np
import question_engine as qeng
import xml.etree.ElementTree as ET
import cv2
from tqdm import tqdm
import copy
"""
Generate synthetic questions and answers for CLEVR images. Input is a single
JSON file containing ground-truth scene information for all images, and output
is a single JSON file containing all generated questions, answers, and programs.

Questions are generated by expanding templates. Each template contains a single
program template and one or more text templates, both with the same set of typed
slots; by convention <Z> = Size, <C> = Color, <M> = Material, <S> = Shape.

Program templates may contain special nodes that expand into multiple functions
during instantiation; for example a "filter" node in a program template will
expand into a combination of "filter_size", "filter_color", "filter_material",
and "filter_shape" nodes after instantiation, and a "filter_unique" node in a
template will expand into some combination of filtering nodes followed by a
"unique" node.

Templates are instantiated using depth-first search; we are looking for template
instantiations where (1) each "unique" node actually refers to a single object,
(2) constraints in the template are satisfied, and (3) the answer to the question
passes our rejection sampling heuristics.

To efficiently handle (1) and (2), we keep track of partial evaluations of the
program during each step of template expansion. This together with the use of
composite nodes in program templates (filter_unique, relate_filter_unique) allow
us to efficiently prune the search space and terminate early when we know that
(1) or (2) will be violated.
"""



parser = argparse.ArgumentParser()

# Inputs
parser.add_argument('--RAVEN_src_file', default='./RAVEN',
                    help="RAVEN Source File")
parser.add_argument('--metadata_file', default='./metadata.json',
                    help="JSON file containing metadata about functions")
parser.add_argument('--synonyms_json', default='./synonyms.json',
                    help="JSON file defining synonyms for parameter values")
parser.add_argument('--template_dir', default='Direct_Answer_templates_normal',
                    help="Directory containing JSON templates for questions")
# # Output
# parser.add_argument('--output_questions_file',
#                     default='./output/RAVEN_questions.json',
#                     help="The output file to write containing generated questions")
parser.add_argument('--output_dir',
                    default='./dataset/',
                    help="The output directory to write")
parser.add_argument('--images_per_configuration', default=1000, type=int,
                    help="The number of images per configuration")
# Control the number of questions per image; we will attempt to generate
# templates_per_image * instances_per_template questions per image.
parser.add_argument('--templates_per_image', default=100, type=int,
                    help="The number of different templates that should be instantiated " +
                         "on each image")
parser.add_argument('--instances_per_template', default=1, type=int,
                    help="The number of times each template should be instantiated on an image")

# Misc
parser.add_argument('--reset_counts_every', default=250, type=int,
                    help="How often to reset template and answer counts. Higher values will " +
                         "result in flatter distributions over templates and answers, but " +
                         "will result in longer runtimes.")
parser.add_argument('--verbose', action='store_true', default=False,
                    help="Print more verbose output")
parser.add_argument('--seed', default=0, type=int,
                    help="seed")

def precompute_filter_options(instance_struct, metadata, panel_idx, attr_keys):
    # Keys are tuples (size, color, shape, material) (where some may be None)
    # and values are lists of object idxs that match the filter criterion
    attribute_map = {}
    # Precompute masks
    masks = []
    attr_keys = [attr_keys]
    for i in range(2 ** len(attr_keys)):
        mask = []
        for j in range(len(attr_keys)):
            mask.append((i // (2 ** j)) % 2)
        masks.append(mask)

    for object_idx, obj in enumerate(instance_struct['panels'][panel_idx]):
        keys = [tuple(obj[k.lower()] for k in attr_keys)]

        for mask in masks:
            for key in keys:
                masked_key = []
                for a, b in zip(key, mask):
                    if b == 1:
                        masked_key.append(a)
                    else:
                        masked_key.append(None)
                masked_key = tuple(masked_key)
                if masked_key not in attribute_map:
                    attribute_map[masked_key] = set()
                attribute_map[masked_key].add(object_idx)

    del attribute_map[(None,)]

    instance_struct['_filter_options'][panel_idx][attr_keys[0]] = attribute_map


def find_filter_options(objects, instance_struct, metadata, panel_idx, attribute):
    # Keys are tuples (size, color, shape, material) (where some may be None)
    # and values are lists of object idxs that match the filter criterion

    if '_filter_options' not in instance_struct:
        filter_options = {}
        for idx, panel_num in enumerate(instance_struct['panels']):
            filter_options[idx] = {}
            for att in ["Shape", "Position"]:
                filter_options[idx][att] = {}
        instance_struct["_filter_options"] = filter_options
        precompute_filter_options(instance_struct, metadata, panel_idx, attribute)
    elif '_filter_options' in instance_struct and len(instance_struct['_filter_options'][panel_idx][attribute]) == 0:
        precompute_filter_options(instance_struct, metadata, panel_idx, attribute)

    attribute_map = {}
    for k, vs in instance_struct['_filter_options'][panel_idx][attribute].items():
        attribute_map[k] = sorted(list(vs))
    return attribute_map


def add_empty_filter_options(attribute_map, metadata, num_to_add, attribute):
    # Add some filtering criterion that do NOT correspond to objects

    attr_vals = [metadata['types'][attribute] + [None]]
    if '_filter_options' in metadata:
        attr_vals = metadata['_filter_options']

    target_size = len(attribute_map) + num_to_add
    while len(attribute_map) < target_size:
        k = (random.choice(v) for v in attr_vals)
        if k not in attribute_map:
            attribute_map[k] = []


def find_relate_filter_options(object_idx, scene_struct, metadata,
                               unique=False, include_zero=False, trivial_frac=0.1):
    options = {}
    if '_filter_options' not in scene_struct:
        precompute_filter_options(scene_struct, metadata)

    # TODO: Right now this is only looking for nontrivial combinations; in some
    # cases I may want to add trivial combinations, either where the intersection
    # is empty or where the intersection is equal to the filtering output.
    trivial_options = {}
    for relationship in scene_struct['relationships']:
        related = set(scene_struct['relationships'][relationship][object_idx])
        for filters, filtered in scene_struct['_filter_options'].items():
            intersection = related & filtered
            trivial = (intersection == filtered)
            if unique and len(intersection) != 1: continue
            if not include_zero and len(intersection) == 0: continue
            if trivial:
                trivial_options[(relationship, filters)] = sorted(list(intersection))
            else:
                options[(relationship, filters)] = sorted(list(intersection))

    N, f = len(options), trivial_frac
    num_trivial = int(round(N * f / (1 - f)))
    trivial_options = list(trivial_options.items())
    random.shuffle(trivial_options)
    for k, v in trivial_options[:num_trivial]:
        options[k] = v

    return options


def node_shallow_copy(node):
    new_node = {
        'type': node['type'],
        'inputs': node['inputs'],
    }
    if 'side_inputs' in node:
        new_node['side_inputs'] = node['side_inputs']
    return new_node


def other_heuristic(text, param_vals):
    """
    Post-processing heuristic to handle the word "other"
    """
    if ' other ' not in text and ' another ' not in text:
        return text
    target_keys = {
        '<Z>',  '<C>',  '<M>',  '<S>',
        '<Z2>', '<C2>', '<M2>', '<S2>',
    }
    if param_vals.keys() != target_keys:
        return text
    key_pairs = [
        ('<Z>', '<Z2>'),
        ('<C>', '<C2>'),
        ('<M>', '<M2>'),
        ('<S>', '<S2>'),
    ]
    remove_other = False
    for k1, k2 in key_pairs:
        v1 = param_vals.get(k1, None)
        v2 = param_vals.get(k2, None)
        if v1 != '' and v2 != '' and v1 != v2:
            print('other has got to go! %s = %s but %s = %s'
                  % (k1, v1, k2, v2))
            remove_other = True
            break
    if remove_other:
        if ' other ' in text:
            text = text.replace(' other ', ' ')
        if ' another ' in text:
            text = text.replace(' another ', ' a ')
    return text

def save_image(npz_file, save_dir, idx):
    def save_image(image, filename):
        cv2.imwrite(filename, image)

    def draw_dashed_line(image, start_point, end_point, color, thickness, dash_length=3):
        line_length = int(np.sqrt((end_point[0] - start_point[0]) ** 2 + (end_point[1] - start_point[1]) ** 2))
        for i in range(0, line_length, 2 * dash_length):
            start_dash = (
                int(start_point[0] + (end_point[0] - start_point[0]) * i / line_length),
                int(start_point[1] + (end_point[1] - start_point[1]) * i / line_length)
            )
            end_dash = (
                int(start_point[0] + (end_point[0] - start_point[0]) * (i + dash_length) / line_length),
                int(start_point[1] + (end_point[1] - start_point[1]) * (i + dash_length) / line_length)
            )
            cv2.line(image, start_dash, end_dash, color, thickness)

    def draw_dashed_bounding_box(image, top_left, bottom_right, color, thickness=1, dash_length=3):
        # Draw the top side
        draw_dashed_line(image, top_left, (bottom_right[0], top_left[1]), color, thickness, dash_length)
        # Draw the bottom side
        draw_dashed_line(image, (top_left[0], bottom_right[1]), bottom_right, color, thickness, dash_length)
        # Draw the left side
        draw_dashed_line(image, top_left, (top_left[0], bottom_right[1]), color, thickness, dash_length)
        # Draw the right side
        draw_dashed_line(image, (bottom_right[0], top_left[1]), bottom_right, color, thickness, dash_length)

    # Adjust the add_bounding_boxes function to use dashed bounding boxes
    def add_bounding_boxes(image, img_height, img_width, rows, cols, padding=25, extra_padding=0, vertical_padding=False):
        for col in range(cols):
            for row in range(rows):
                if vertical_padding and row == 1:
                    top_left = (col * (img_width + padding) + extra_padding, row * (img_height + 2 * padding) + extra_padding)
                    bottom_right = (top_left[0] + img_width, top_left[1] + img_height)
                else:
                    top_left = (col * (img_width + padding) + extra_padding, row * (img_height + padding) + extra_padding)
                    bottom_right = (top_left[0] + img_width, top_left[1] + img_height)

                draw_dashed_bounding_box(image, top_left, bottom_right, color=(0, 0, 0), thickness=1)

    def add_numbers_to_panels(image, img_height, img_width, rows, cols):
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.8
        font_thickness = 2
        font_color = (0, 0, 0)

        panel_num = 1
        for row in range(rows):
            for col in range(cols):
                text = str(panel_num)
                text_size = cv2.getTextSize(text, font, font_scale, font_thickness)[0]
                text_x = (col * (img_width + 20) + (img_width - text_size[0]) // 2 + 40)  # Added padding
                text_y = (row * (img_height + 40) + img_height + 65)  # Adjusted position for padding
                cv2.putText(image, text, (int(text_x), int(text_y)), font, font_scale, font_color, font_thickness)
                panel_num += 1

    def add_vertical_text(image, text, font=cv2.FONT_HERSHEY_SIMPLEX, font_scale=0.8, font_thickness=2, padding=10, answer_set=False):
        """
        Adds horizontal text at the top of the image.
        """
        # Create a blank white image for the text
        if answer_set:
            text_size, _ = cv2.getTextSize(text, font, font_scale, font_thickness)
            text_width, text_height = text_size
            padded_height = image.shape[0] + text_height
            padded_width = image.shape[1]

            # Create the padded canvas for the image
            padded_image = np.ones((padded_height, padded_width), dtype=np.uint8) * 255
            padded_image[text_height:] = image

            # Add horizontal text to the top of the image
            text_x = (padded_width - text_width) // 2
            text_y = text_height + 20  # Adjust vertical position if needed
            cv2.putText(padded_image, text, (text_x, text_y), font, font_scale, 0, font_thickness)

        else:
            text_size, _ = cv2.getTextSize(text, font, font_scale, font_thickness)
            text_width, text_height = text_size
            padded_height = image.shape[0] + padding + text_height
            padded_width = image.shape[1]

            # Create the padded canvas for the image
            padded_image = np.ones((padded_height, padded_width), dtype=np.uint8) * 255
            padded_image[padding + text_height:] = image

            # Add horizontal text to the top of the image
            text_x = (padded_width - text_width) // 2
            text_y = padding + text_height  # Adjust vertical position if needed
            cv2.putText(padded_image, text, (text_x, text_y), font, font_scale, 0, font_thickness)

        return padded_image

    def extract_and_save_images(big_image_3x3_clean, img_height, img_width, output_dir,
                                padding=25, extra_padding=30):
        os.makedirs(output_dir, exist_ok=True)

        # 1. Save each individual panel from the 3x3 grid (except the question mark panel)
        panel_num = 1
        for row in range(3):
            for col in range(3):
                if row == 2 and col == 2:
                    continue  # Skip the question mark panel
                start_y = row * (img_height + padding)
                start_x = col * (img_width + padding)
                panel = big_image_3x3_clean[start_y:start_y + img_height, start_x:start_x + img_width]
                # Add extra padding around the panel

                # Add extra padding around the panel
                panel_with_padding = np.ones((img_height + 2 * extra_padding, img_width + 2 * extra_padding),
                                             dtype=np.uint8) * 255
                panel_with_padding[extra_padding:extra_padding + img_height,
                extra_padding:extra_padding + img_width] = panel
                add_bounding_boxes(panel_with_padding, img_height, img_width, 1, 1, padding, extra_padding=extra_padding)
                save_image(panel_with_padding, os.path.join(output_dir, f'panel_{panel_num}.png'))
                panel_num += 1

        # 2. Save combinations of two panels within the same row
        combinations = [(1, 2), (1, 3), (2, 3), (4, 5), (5, 6), (4, 6), (7, 8)]
        for combo in combinations:
            panel1 = combo[0] - 1
            panel2 = combo[1] - 1

            row1 = panel1 // 3
            col1 = panel1 % 3
            row2 = panel2 // 3
            col2 = panel2 % 3

            start_y1 = row1 * (img_height + padding)
            start_x1 = col1 * (img_width + padding)
            start_y2 = row2 * (img_height + padding)
            start_x2 = col2 * (img_width + padding)

            combined_image = np.ones((img_height + 2*extra_padding, 2 * img_width + padding + 2*extra_padding), dtype=np.uint8) * 255
            combined_image[extra_padding:extra_padding+img_height, extra_padding:img_width+extra_padding] = big_image_3x3_clean[start_y1:start_y1 + img_height,
                                            start_x1:start_x1 + img_width]
            combined_image[extra_padding:extra_padding+img_height, img_width + padding + extra_padding:2 * img_width + padding + extra_padding] = big_image_3x3_clean[start_y2:start_y2 + img_height,
                                                      start_x2:start_x2 + img_width]

            # Draw bounding box around combined image
            draw_dashed_bounding_box(combined_image, (extra_padding, extra_padding), (img_width+extra_padding, img_height+extra_padding), color=(0, 0, 0), thickness=1)
            draw_dashed_bounding_box(combined_image, (img_width + padding + extra_padding, extra_padding), (2 * img_width + padding + extra_padding, img_height + extra_padding),
                                     color=(0, 0, 0), thickness=1)
            save_image(combined_image, os.path.join(output_dir, f'panel_combination_{combo[0]}_{combo[1]}.png'))

        # 3. Save each row in the 3x3 grid with padding
        for row in range(2):
            row_image = big_image_3x3_clean[row * (img_height + padding):(row + 1) * (img_height + padding) - padding,
                        :3 * img_width + 2 * padding].copy()
            # Add extra padding to the top and bottom of the row image
            row_image_with_padding = np.ones((row_image.shape[0] + 2 * extra_padding, row_image.shape[1] + 2 * extra_padding),
                                             dtype=np.uint8) * 255
            row_image_with_padding[extra_padding:extra_padding + row_image.shape[0], extra_padding:extra_padding + row_image.shape[1]] = row_image
            add_bounding_boxes(row_image_with_padding, img_height, img_width, 1, 3, padding, extra_padding = extra_padding)
            save_image(row_image_with_padding, os.path.join(output_dir, f'row_{row + 1}.png'))

        # 4. Save the first two rows combined
        first_two_rows_image = big_image_3x3_clean[:2 * (img_height + padding) - padding,
                               :3 * img_width + 2 * padding].copy()
        first_two_rows_image_with_padding = np.ones(
            (first_two_rows_image.shape[0] + 2 * extra_padding, first_two_rows_image.shape[1] + 2 * extra_padding),
            dtype=np.uint8) * 255
        first_two_rows_image_with_padding[extra_padding:extra_padding + first_two_rows_image.shape[0],
        extra_padding:extra_padding + first_two_rows_image.shape[1]] = first_two_rows_image
        add_bounding_boxes(first_two_rows_image_with_padding, img_height, img_width, 2, 3, padding, extra_padding=extra_padding)
        save_image(first_two_rows_image_with_padding, os.path.join(output_dir, 'first_two_rows.png'))


    # Load images and generate the grid
    images = npz_file['image']

    # Assuming the images are all of the same size
    img_height, img_width = images[0].shape

    # Padding between the panels
    padding = 20  # Set to the value you want
    extra_padding = 20
    # Create blank canvases for the 3x3 grid with padding
    big_image_3x3_clean = np.ones((3 * img_height + 2 * padding, 3 * img_width + 2 * padding), dtype=np.uint8) * 255

    # Place the first 8 images into the 3x3 grid
    for i in range(8):
        row = i // 3
        col = i % 3
        start_y = row * (img_height + padding)
        start_x = col * (img_width + padding)
        big_image_3x3_clean[start_y:start_y + img_height, start_x:start_x + img_width] = images[i]

    # Draw a question mark in the last (9th) panel
    question_mark_image = np.ones((img_height, img_width), dtype=np.uint8) * 255
    font = cv2.FONT_HERSHEY_SIMPLEX
    font_scale = 3
    font_thickness = 5
    (text_width, text_height), baseline = cv2.getTextSize('?', font, font_scale, font_thickness)
    text_x = (img_width - text_width) // 2
    text_y = (img_height + text_height) // 2
    cv2.putText(question_mark_image, '?', (text_x, text_y), font, font_scale, 0, font_thickness)
    big_image_3x3_clean[2 * (img_height + padding):3 * (img_height + padding),
    2 * (img_width + padding):3 * (img_width + padding)] = question_mark_image

    # Create a copy of the clean grid with bounding boxes added
    big_image_3x3_dashed = np.ones((3 * img_height + 2 * padding + 2 * extra_padding, 3 * img_width + 2 * padding + 2 * extra_padding), dtype=np.uint8) * 255

    big_image_3x3_dashed[extra_padding:big_image_3x3_clean.shape[0]+extra_padding, extra_padding:big_image_3x3_clean.shape[1]+extra_padding] = big_image_3x3_clean.copy()
    add_bounding_boxes(big_image_3x3_dashed, img_height, img_width, 3, 3, padding, extra_padding=extra_padding)

    # Extract and save images as per the requirements
    extract_and_save_images(big_image_3x3_clean, img_height, img_width, save_dir, padding)

    cv2.imwrite(save_dir + "/question.png", big_image_3x3_dashed)

    answer_extra_padding = 40
    big_image_2x4 = np.ones((2 * img_height + 2 * padding + 2 * answer_extra_padding, 4 * img_width + 3 * padding + 2 * answer_extra_padding), dtype=np.uint8) * 255
    for i in range(8):
        row = i // 4
        col = i % 4
        start_y = row * (img_height + 2*padding) + answer_extra_padding
        start_x = col * (img_width + padding) + answer_extra_padding
        big_image_2x4[start_y:start_y + img_height, start_x:start_x + img_width] = images[i+8]

    add_bounding_boxes(big_image_2x4, img_height, img_width, 2, 4, padding, extra_padding=answer_extra_padding, vertical_padding=True)
    question_image = big_image_3x3_dashed
    answer_image = big_image_2x4

    add_numbers_to_panels(answer_image, img_height, img_width, 2 ,4)

    question_image_with_title = add_vertical_text(question_image, "Problem Matrix", padding=20)
    answer_image_with_title = add_vertical_text(answer_image, "Answer Set", padding=20, answer_set=True)

    question_width_with_title = question_image_with_title.shape[1]
    answer_width_with_title = answer_image_with_title.shape[1]

    # Find the maximum width
    # Find the maximum width
    max_width = max(question_width_with_title, answer_width_with_title)

    # Pad the smaller image to center it
    if question_width_with_title < max_width:
        total_padding = max_width - question_width_with_title
        left_padding = total_padding // 2
        right_padding = total_padding - left_padding
        question_image_with_title = np.pad(question_image_with_title, ((0, 0), (left_padding, right_padding)),
                                           mode='constant', constant_values=255)


    # Concatenate the images vertically
    combined_image = np.vstack((question_image_with_title, answer_image_with_title))

    # Save the combined image
    cv2.imwrite(save_dir + "/combined.png", combined_image)

def instantiate_templates_dfs(instance_struct, template, metadata,
                              synonyms, config, fn, max_instances=None, verbose=False):

    param_name_to_type = {p['name']: p['type'] for p in template['params']}

    initial_state = {
        'nodes': [node_shallow_copy(template['nodes'][0])],
        'vals': {},
        'input_map': {0: 0},
        'next_template_node': 1,
    }
    states = [initial_state]
    final_states = []
    while states:
        state = states.pop()
        if "<P>" in state["vals"].keys():
            cur_panel = state["vals"]["<P>"]
        # Check to make sure the current state is valid
        q = {'nodes': state['nodes']}
        outputs = qeng.answer_question(q, metadata, instance_struct, all_outputs=True)
        answer = outputs[-1]
        if answer == '__INVALID__': continue

        # Check to make sure constraints are satisfied for the current state
        skip_state = False
        for constraint in template['constraints']:
            if constraint['type'] == 'NEQ':
                p1, p2 = constraint['params']
                v1, v2 = state['vals'].get(p1), state['vals'].get(p2)
                if v1 is not None and v2 is not None and v1 != v2:
                    if verbose:
                        print('skipping due to NEQ constraint')
                        print(constraint)
                        print(state['vals'])
                    skip_state = True
                    break
            elif constraint['type'] == 'NULL':
                p = constraint['params'][0]
                p_type = param_name_to_type[p]
                v = state['vals'].get(p)
                if v is not None:
                    skip = False
                    if p_type == 'Shape' and v != 'thing': skip = True
                    if p_type != 'Shape' and v != '': skip = True
                    if skip:
                        if verbose:
                            print('skipping due to NULL constraint')
                            print(constraint)
                            print(state['vals'])
                        skip_state = True
                        break
            elif constraint['type'] == 'OUT_NEQ':
                i, j = constraint['params']
                i = state['input_map'].get(i, None)
                j = state['input_map'].get(j, None)
                if i is not None and j is not None and outputs[i] == outputs[j]:
                    if verbose:
                        print('skipping due to OUT_NEQ constraint')
                        print(outputs[i])
                        print(outputs[j])
                    skip_state = True
                    break
            elif constraint['type'] == 'EQUAL':
                i, j = constraint['params']
                i = state['input_map'].get(i, None)
                j = state['input_map'].get(j, None)
                if i is not None and j is not None and outputs[i] != outputs[j]:
                    if verbose:
                        print('skipping due to EQUAL constraint')
                        print(outputs[i])
                        print(outputs[j])
                    skip_state = True
                    break
            elif constraint['type'] == 'SAME_ROW':
                i, j = constraint['params']
                i = state['input_map'].get(i, None)
                j = state['input_map'].get(j, None)
                if i is not None and j is not None:
                    first_panel_num = state['nodes'][i]['side_inputs'][0]
                    second_panel_num = state['nodes'][j]['side_inputs'][0]
                    row1 = first_panel_num // 3
                    row2 = second_panel_num // 3
                    if row1 != row2 or first_panel_num == second_panel_num:
                        if verbose:
                            print('skipping due to SAME_ROW constraint')
                            print(outputs[i])
                            print(outputs[j])
                        skip_state = True
                        break
            else:
                assert False, 'Unrecognized constraint type "%s"' % constraint['type']

        if skip_state:
            continue

        # We have already checked to make sure the answer is valid, so if we have
        # processed all the nodes in the template then the current state is a valid
        # question, so add it if it passes our rejection sampling tests.
        if state['next_template_node'] == len(template['nodes']):
            # Use our rejection sampling heuristics to decide whether we should
            # keep this template instantiation
            # cur_answer_count = answer_counts[answer]
            # answer_counts_sorted = sorted(answer_counts.values())
            # median_count = answer_counts_sorted[len(answer_counts_sorted) // 2]
            # median_count = max(median_count, 5)
            # if cur_answer_count > 1.1 * answer_counts_sorted[-2]:
            #     if verbose: print('skipping due to second count')
            #     continue
            # if cur_answer_count > 5.0 * median_count:
            #     if verbose: print('skipping due to median')
            #     continue
            #
            # # If the template contains a raw relate node then we need to check for
            # # degeneracy at the end
            # has_relate = any(n['type'] == 'relate' for n in template['nodes'])
            # if has_relate:
            #     degen = qeng.is_degenerate(q, metadata, instance_struct, answer=answer,
            #                                verbose=verbose)
            #     if degen:
            #         continue
            #
            # answer_counts[answer] += 1
            state['answer'] = answer
            final_states.append(state)
            if max_instances is not None and len(final_states) == max_instances:
                break
            continue

        # Otherwise fetch the next node from the template
        # Make a shallow copy so cached _outputs don't leak ... this is very nasty
        next_node = template['nodes'][state['next_template_node']]
        next_node = node_shallow_copy(next_node)

        special_nodes = {
            'filter_unique', 'filter_count', 'filter_exist', 'filter'
        }
        if next_node['type'] in special_nodes:
            filter_options = find_filter_options(answer, instance_struct, metadata, cur_panel, param_name_to_type[next_node['side_inputs'][0]])
            if next_node['type'] == 'filter':
                # Remove null filter
                filter_options.pop((None, None, None, None), None)
            if next_node['type'] == 'filter_unique':
                # Get rid of all filter options that don't result in a single object
                filter_options = {k: v for k, v in filter_options.items()
                                  if len(v) == 1}
            else:
                # Add some filter options that do NOT correspond to the scene
                if next_node['type'] == 'filter_exist':
                    # For filter_exist we want an equal number that do and don't
                    num_to_add = len(filter_options)
                elif next_node['type'] == 'filter_count' or next_node['type'] == 'filter':
                    # For filter_count add nulls equal to the number of singletons
                    num_to_add = 0
                add_empty_filter_options(filter_options, metadata, num_to_add, param_name_to_type[next_node['side_inputs'][0]])

            filter_option_keys = list(filter_options.keys())
            random.shuffle(filter_option_keys)
            for k in filter_option_keys:
                new_nodes = []
                cur_next_vals = {k: v for k, v in state['vals'].items()}
                next_input = state['input_map'][next_node['inputs'][0]]
                filter_side_inputs = next_node['side_inputs']
                if next_node['type'].startswith('relate'):
                    param_name = next_node['side_inputs'][0] # First one should be relate
                    filter_side_inputs = next_node['side_inputs'][1:]
                    param_type = param_name_to_type[param_name]
                    assert param_type == 'Relation'
                    param_val = k[0]
                    k = k[1]
                    new_nodes.append({
                        'type': 'relate',
                        'inputs': [next_input],
                        'side_inputs': [param_val],
                    })
                    cur_next_vals[param_name] = param_val
                    next_input = len(state['nodes']) + len(new_nodes) - 1
                for param_name, param_val in zip(filter_side_inputs, k):
                    param_type = param_name_to_type[param_name]
                    filter_type = 'filter_%s' % param_type.lower()
                    if param_val is not None:
                        new_nodes.append({
                            'type': filter_type,
                            'inputs': [next_input],
                            'side_inputs': [param_val],
                        })
                        cur_next_vals[param_name] = param_val
                        next_input = len(state['nodes']) + len(new_nodes) - 1
                    elif param_val is None:
                        if metadata['dataset'] == 'CLEVR-v1.0' and param_type == 'Shape':
                            param_val = 'thing'
                        else:
                            param_val = ''
                        cur_next_vals[param_name] = param_val
                input_map = {k: v for k, v in state['input_map'].items()}
                extra_type = None
                if next_node['type'].endswith('unique'):
                    extra_type = 'unique'
                if next_node['type'].endswith('count'):
                    extra_type = 'count'
                if next_node['type'].endswith('exist'):
                    extra_type = 'exist'
                if extra_type is not None:
                    new_nodes.append({
                        'type': extra_type,
                        'inputs': [input_map[next_node['inputs'][0]] + len(new_nodes)],
                    })
                input_map[state['next_template_node']] = len(state['nodes']) + len(new_nodes) - 1
                states.append({
                    'nodes': state['nodes'] + new_nodes,
                    'vals': cur_next_vals,
                    'input_map': input_map,
                    'next_template_node': state['next_template_node'] + 1,
                })

        elif 'side_inputs' in next_node:
            # If the next node has template parameters, expand them out
            # TODO: Generalize this to work for nodes with more than one side input
            assert len(next_node['side_inputs']) == 1, 'NOT IMPLEMENTED'

            # Use metadata to figure out domain of valid values for this parameter.
            # Iterate over the values in a random order; then it is safe to bail
            # from the DFS as soon as we find the desired number of valid template
            # instantiations.
            param_name = next_node['side_inputs'][0]
            param_type = param_name_to_type[param_name]
            param_vals = metadata['types'][param_type][:]

            random.shuffle(param_vals)

            for val in param_vals:
                input_map = {k: v for k, v in state['input_map'].items()}
                input_map[state['next_template_node']] = len(state['nodes'])
                cur_next_node = {
                    'type': next_node['type'],
                    'inputs': [input_map[idx] for idx in next_node['inputs']],
                    'side_inputs': [val],
                }
                cur_next_vals = {k: v for k, v in state['vals'].items()}
                cur_next_vals[param_name] = val

                states.append({
                    'nodes': state['nodes'] + [cur_next_node],
                    'vals': cur_next_vals,
                    'input_map': input_map,
                    'next_template_node': state['next_template_node'] + 1,
                })
        else:
            input_map = {k: v for k, v in state['input_map'].items()}
            input_map[state['next_template_node']] = len(state['nodes'])
            next_node = {
                'type': next_node['type'],
                'inputs': [input_map[idx] for idx in next_node['inputs']],
            }
            states.append({
                'nodes': state['nodes'] + [next_node],
                'vals': state['vals'],
                'input_map': input_map,
                'next_template_node': state['next_template_node'] + 1,
            })

    # Actually instantiate the template with the solutions we've found
    text_questions, structured_questions, answers, choices = [], [], [], []
    for state in final_states:
        # if state["nodes"][-1]["type"] == "query_position" and config == "center_single":
        #     break
        structured_questions.append(state['nodes'])
        answers.append(state['answer'])
        text = random.choice(template['text'])
        for name, val in state['vals'].items():
            if val in synonyms:
                val = random.choice(synonyms[val])
            if name == '<P>' or name == '<P2>':
                val += 1
            text = text.replace(name, str(val))
            text = ' '.join(text.split())
        text = replace_optionals(text)
        text = ' '.join(text.split())
        text = other_heuristic(text, state['vals'])
        text_questions.append(text)
        text_questions = [replace_panel_phrases(question) for question in text_questions]

        if state["nodes"][-1]["type"] == "query_position":
            num_choices = template["answers_number"][config]
        else:
            num_choices = template["answers_number"]

        # Initialize the list of choices with the correct answer
        choices.append(state['answer'])
        new_template = copy.deepcopy(template)
        if state["nodes"][-1]["type"] == "query_position":
            template_choices = new_template["answer_space"][config]
        else:
            template_choices = new_template["answer_space"]
        filtered_choices = filter_choices(template_choices, fn, state, instance_struct)
        # Randomly sample other choices from metadata[attribute], avoiding duplicates
        while len(choices) < num_choices:
            random_choice = random.choice(filtered_choices)
            if random_choice != state['answer'] and random_choice not in choices:
                choices.append(random_choice)

        # Shuffle the choices to ensure the correct answer isn't always first
        random.shuffle(choices)
    if state["nodes"][-1]['type'] == "query_position":
        choices.append("Not exist in the panel.")
    if state["nodes"][-1]['type'] == "compare_position":
        choices.append("Some queried objects are missing from the panel.")
    assert(len(final_states) <= 1)
    if len(choices) > 0 and len(answers) > 0:
        choices, answers = format_choices_and_answer(choices, answers)
    return text_questions, structured_questions, answers, choices, state['vals']

def filter_choices(candidate_choices, stage, state, instance_struct):
    if "reasoning_first" in stage:
        first_panel = instance_struct['panels'][0]
        second_panel = instance_struct['panels'][1]
        third_panel = instance_struct['panels'][2]
        if state["nodes"][0]['type'] == 'query_number_rule':
            # progression
            if "The number of objects gradually" in state["answer"]:
                candidate_choices.remove("The number of objects distributes three distinct values across panels, rotating through each possible permutation of these values.")
                if len(first_panel) + len(second_panel) == len(third_panel):
                    candidate_choices.remove("The number of objects in the last panel equals the sum of the objects in the previous two panels.")
                if len(first_panel) - len(second_panel) == len(third_panel):
                    candidate_choices.remove("The number of objects in the last panel equals the difference between the objects in the previous two panels.")
            # Arithmetic
            elif "The number of objects in the last panel equals" in state["answer"]:
                if len(first_panel) != len(second_panel) and len(first_panel) != len(third_panel) and len(second_panel) != len(third_panel):
                    candidate_choices.remove("The number of objects distributes three distinct values across panels, rotating through each possible permutation of these values.")
                if len(second_panel) == len(first_panel) + 1 and len(third_panel) == len(second_panel) + 1:
                    candidate_choices.remove("The number of objects gradually increases by 1.")
                if len(second_panel) == len(first_panel) - 1 and len(third_panel) == len(second_panel) - 1:
                    candidate_choices.remove("The number of objects gradually decreases by 1.")
            elif "The number of objects distributes three" in state["answer"]:
                if len(first_panel) + len(second_panel) == len(third_panel):
                    candidate_choices.remove("The number of objects in the last panel equals the sum of the objects in the previous two panels.")
                if len(first_panel) - len(second_panel) == len(third_panel):
                    candidate_choices.remove("The number of objects in the last panel equals the difference between the objects in the previous two panels.")
                if len(second_panel) == len(first_panel) + 1 and len(third_panel) == len(second_panel) + 1:
                    candidate_choices.remove("The number of objects gradually increases by 1.")
                if len(second_panel) == len(first_panel) - 1 and len(third_panel) == len(second_panel) - 1:
                    candidate_choices.remove("The number of objects gradually decreases by 1.")
        elif state["nodes"][0]['type'] == 'query_position_rule':
            if ("If an object is in the first panel" in state["answer"]) or ("The position of objects in the last panel" in state["answer"]):
                candidate_choices.remove("Three distinct position settings across panels, rotating through each possible permutation of these settings.")
        elif state["nodes"][0]['type'] == 'query_shape_rule':
            TYPE_VALUES = {"triangle": 1, "square": 2, "pentagon": 3, "hexagon": 4, "circle": 5}
            if "The edge number of shape gradually" in state["answer"]:
                candidate_choices.remove("Three distinct shapes across panels, rotating through each possible permutation of these shapes.")
            elif "Three distinct shapes across panels, rotating through each possible permutation of these shapes." in state["answer"]:
                if TYPE_VALUES[second_panel[0]["shape"]] == TYPE_VALUES[first_panel[0]["shape"]] + 1 and TYPE_VALUES[third_panel[0]["shape"]] == TYPE_VALUES[second_panel[0]["shape"]] + 1:
                    candidate_choices.remove("The edge number of shape gradually increases by 1.")
                if TYPE_VALUES[second_panel[0]["shape"]] == TYPE_VALUES[first_panel[0]["shape"]] - 1 and TYPE_VALUES[third_panel[0]["shape"]] == TYPE_VALUES[second_panel[0]["shape"]] - 1:
                    candidate_choices.remove("The edge number of shape gradually decreases by 1.")
        elif state["nodes"][0]['type'] == 'query_size_rule':
            SIZE_VALUES = [0.4, 0.5, 0.6, 0.7, 0.8, 0.9]
            first_panel_size = SIZE_VALUES.index(first_panel[0]["size"]) + 1
            second_panel_size = SIZE_VALUES.index(second_panel[0]["size"]) + 1
            third_panel_size = SIZE_VALUES.index(third_panel[0]["size"]) + 1
            if "The size of objects gradually" in state["answer"]:
                candidate_choices.remove("Three distinct sizes across panels, rotating through each possible permutation of these sizes.")
                if first_panel_size + second_panel_size == third_panel_size:
                    candidate_choices.remove("The size of objects in the last panel is the sum of the sizes in the previous two panels.")
                if first_panel_size - second_panel_size == third_panel_size:
                    candidate_choices.remove("The size of objects in the last panel is the difference between the sizes in the previous two panels.")
            elif "The size of objects in the last panel" in state["answer"]:
                if first_panel_size != second_panel_size and first_panel_size != third_panel_size and second_panel_size != third_panel_size:
                    candidate_choices.remove("Three distinct sizes across panels, rotating through each possible permutation of these sizes.")
                if second_panel_size == first_panel_size + 1 and third_panel_size == second_panel_size + 1:
                    candidate_choices.remove("The size of objects gradually increases by a constant amount each time.")
                if second_panel_size == first_panel_size - 1 and third_panel_size == second_panel_size - 1:
                    candidate_choices.remove("The size of objects gradually decreases by a constant amount each time.")
            elif "Three distinct sizes across panels, rotating through each possible permutation of these sizes." in state["answer"]:
                if first_panel_size + second_panel_size == third_panel_size:
                    candidate_choices.remove("The size of objects in the last panel is the sum of the sizes in the previous two panels.")
                if first_panel_size - second_panel_size == third_panel_size:
                    candidate_choices.remove("The size of objects in the last panel is the difference between the sizes in the previous two panels.")
                if second_panel_size == first_panel_size + 1 and third_panel_size == second_panel_size + 1:
                    candidate_choices.remove("The size of objects gradually increases by a constant amount each time.")
                if second_panel_size == first_panel_size - 1 and third_panel_size == second_panel_size - 1:
                    candidate_choices.remove("The size of objects gradually decreases by a constant amount each time.")
        elif state["nodes"][0]['type'] == 'query_color_rule':
            COLOR_VALUES = [255, 224, 196, 168, 140, 112, 84, 56, 28, 0]
            first_panel_color = COLOR_VALUES.index(first_panel[0]["color"]) + 1
            second_panel_color = COLOR_VALUES.index(second_panel[0]["color"]) + 1
            third_panel_color = COLOR_VALUES.index(third_panel[0]["color"]) + 1
            if "The color of objects gradually" in state["answer"]:
                candidate_choices.remove("Three distinct colors across panels, rotating through each possible permutation of these colors.")
                if first_panel_color + second_panel_color == third_panel_color:
                    candidate_choices.remove("The color of objects in the last panel is the sum of the colors in the previous two panels.")
                if first_panel_color - second_panel_color == third_panel_color:
                    candidate_choices.remove("The color of objects in the last panel is the difference between the colors in the previous two panels.")
            elif "The color of objects in the last panel" in state["answer"]:
                if first_panel_color != second_panel_color and first_panel_color != third_panel_color and second_panel_color != third_panel_color:
                    candidate_choices.remove("Three distinct colors across panels, rotating through each possible permutation of these colors.")
                if second_panel_color == first_panel_color + 1 and third_panel_color == second_panel_color + 1:
                    candidate_choices.remove("The color of objects gradually darkens by a constant amount each time.")
                if second_panel_color == first_panel_color - 1 and third_panel_color == second_panel_color - 1:
                    candidate_choices.remove("The color of objects gradually brightens by a constant amount each time.")
            elif "Three distinct colors across panels, rotating through each possible permutation of these colors." in state["answer"]:
                if first_panel_color + second_panel_color == third_panel_color:
                    candidate_choices.remove("The color of objects in the last panel is the sum of the colors in the previous two panels.")
                if first_panel_color - second_panel_color == third_panel_color:
                    candidate_choices.remove("The color of objects in the last panel is the difference between the colors in the previous two panels.")
                if second_panel_color == first_panel_color + 1 and third_panel_color == second_panel_color + 1:
                    candidate_choices.remove("The color of objects gradually darkens by a constant amount each time.")
                if second_panel_color == first_panel_color - 1 and third_panel_color == second_panel_color - 1:
                    candidate_choices.remove("The color of objects gradually brightens by a constant amount each time.")
    return candidate_choices

def format_choices_and_answer(choices, answer):
    # Define the labels
    labels = ['A:', 'B:', 'C:', 'D:']

    # Function to capitalize each part of a hyphenated word
    def capitalize_hyphenated(choice):
        if isinstance(choice, str) and not choice.isdigit():
            # Capitalize each part of the hyphenated word
            return '-'.join([part.capitalize() for part in choice.split('-')])
        return choice  # Return numbers or non-strings as is

    # Format the choices with labels and capitalize non-numeric choices
    formatted_choices = [
        f"{labels[i]} {capitalize_hyphenated(choice)}"
        for i, choice in enumerate(choices)
    ]

    # Map the answer to its corresponding label
    choice_dict = {choice: labels[i] for i, choice in enumerate(choices)}
    formatted_answer = choice_dict.get(answer[0], None)[0]

    return formatted_choices, formatted_answer


def replace_panel_phrases(text):
    # Find all occurrences of "panel <P>" where <P> is a number
    panels = re.findall(r'panel (\d+)', text)

    # Convert the panel numbers to integers
    panels = list(map(int, panels))

    if len(panels) == 2:
        # Determine which panel number is larger
        larger_panel, smaller_panel = max(panels), min(panels)

        # Replace the panel numbers with "right panel" and "left panel"
        text = re.sub(rf'panel {larger_panel}', 'right panel', text)
        text = re.sub(rf'panel {smaller_panel}', 'left panel', text)

    elif len(panels) == 1:
        # Replace the only "panel <P>" with "this panel"
        text = re.sub(rf'panel {panels[0]}', 'this panel', text)

    return text

def replace_optionals(s):
    """
    Each substring of s that is surrounded in square brackets is treated as
    optional and is removed with probability 0.5. For example the string

    "A [aa] B [bb]"

    could become any of

    "A aa B bb"
    "A  B bb"
    "A aa B "
    "A  B "

    with probability 1/4.
    """
    pat = re.compile(r'\[([^\[]*)\]')

    while True:
        match = re.search(pat, s)
        if not match:
            break
        i0 = match.start()
        i1 = match.end()
        if random.random() > 0.5:
            s = s[:i0] + match.groups()[0] + s[i1:]
        else:
            s = s[:i0] + s[i1:]
    return s


def select_filename(template_name, param_value):
    filename = None
    # Determine the filename based on the template_name and param_value
    if template_name in ['basic.json', 'advanced_one_panel.json']:
        # Rule 1: Single panel
        panel_number = param_value.get('<P>') + 1
        if panel_number is not None:
            filename = f"panel_{panel_number}.png"

    elif "advanced_two_panels" in template_name:
        # Rule 2: Two panels combination
        panel1 = param_value.get('<P>') + 1
        panel2 = param_value.get('<P2>') + 1
        if panel1 is not None and panel2 is not None and panel1 < panel2:
            filename = f"panel_combination_{panel1}_{panel2}.png"
        elif panel1 is not None and panel2 is not None and panel1 > panel2:
            filename = f"panel_combination_{panel2}_{panel1}.png"
    elif "reasoning_first" in template_name:
        # Rule 3: Reasoning first
        filename = f"row_1.png"

    elif "reasoning_second" in template_name:
        # Rule 4: Reasoning second
        filename = f"first_two_rows.png"

    return filename

def main(args):
    random.seed(args.seed)

    with open(args.metadata_file, 'r') as f:
        metadata = json.load(f)

    functions_by_name = {}
    for f in metadata['functions']:
        functions_by_name[f['name']] = f
    metadata['_functions_by_name'] = functions_by_name

    # Load templates from disk
    # Key is (filename, file_idx)
    num_loaded_templates = 0
    templates = {}
    for fn in os.listdir(args.template_dir):
        if not fn.endswith('.json'): continue
        with open(os.path.join(args.template_dir, fn), 'r') as f:
            base = os.path.splitext(fn)[0]
            for i, template in enumerate(json.load(f)):
                num_loaded_templates += 1
                key = (fn, i)
                templates[key] = template
    print('Read %d templates from disk' % num_loaded_templates)

    def reset_counts():
        # Maps a template (filename, index) to the number of questions we have
        # so far using that template
        template_counts = {}
        # Maps a template (filename, index) to a dict mapping the answer to the
        # number of questions so far of that template type with that answer
        template_answer_counts = {}
        node_type_to_dtype = {n['name']: n['output'] for n in metadata['functions']}
        for key, template in templates.items():
            template_counts[key[:2]] = 0
            final_node_type = template['nodes'][-1]['type']
            final_dtype = node_type_to_dtype[final_node_type]
            answers = metadata['types'][final_dtype]
            if final_dtype == 'Bool':
                answers = ["Yes", "No"]
            if final_dtype == 'Integer':
                answers = list(range(0, 11))
            template_answer_counts[key[:2]] = {}
            for a in answers:
                template_answer_counts[key[:2]][a] = 0
        return template_counts, template_answer_counts

    template_counts, template_answer_counts = reset_counts()

    # Read data file
    # all_scenes = []
    # with open(args.input_scene_file, 'r') as f:
    #     scene_data = json.load(f)
    #     all_scenes = scene_data['scenes']
    #     scene_info = scene_data['info']
    # begin = args.scene_start_idx
    # if args.num_scenes > 0:
    #     end = args.scene_start_idx + args.num_scenes
    #     all_scenes = all_scenes[begin:end]
    # else:
    #     all_scenes = all_scenes[begin:]
    def get_position(bbox, config_name):
        if config_name == "Center_Single":
            return "center"
        elif config_name == "Distribute_Four":
            if bbox == '[0.25, 0.25, 0.5, 0.5]':
                return "top-left"
            elif bbox == '[0.25, 0.75, 0.5, 0.5]':
                return "top-right"
            elif bbox == '[0.75, 0.25, 0.5, 0.5]':
                return "bottom-left"
            elif bbox == '[0.75, 0.75, 0.5, 0.5]':
                return "bottom-right"
        elif config_name == "Distribute_Nine":
            if bbox == '[0.16, 0.16, 0.33, 0.33]':
                return "top-left"
            elif bbox == '[0.16, 0.5, 0.33, 0.33]':
                return "top-center"
            elif bbox == '[0.16, 0.83, 0.33, 0.33]':
                return "top-right"
            elif bbox == '[0.5, 0.16, 0.33, 0.33]':
                return "middle-left"
            elif bbox == '[0.5, 0.5, 0.33, 0.33]':
                return "middle-center"
            elif bbox == '[0.5, 0.83, 0.33, 0.33]':
                return "middle-right"
            elif bbox == "[0.83, 0.16, 0.33, 0.33]":
                return "bottom-left"
            elif bbox == "[0.83, 0.5, 0.33, 0.33]":
                return "bottom-center"
            elif bbox == "[0.83, 0.83, 0.33, 0.33]":
                return "bottom-right"
        elif config_name == "Left_Center_Single":
            return "left"
        elif config_name == "Right_Center_Single":
            return "right"
        elif config_name == "Up_Center_Single":
            return "top"
        elif config_name == "Down_Center_Single":
            return "bottom"
        elif config_name == "Out_Center_Single":
            return "outer-part"
        elif config_name == "In_Center_Single":
            return "inner-part"
        elif config_name == "In_Distribute_Four":
            if bbox == "[0.42, 0.42, 0.15, 0.15]":
                return "top-left of the inner part"
            elif bbox == "[0.42, 0.58, 0.15, 0.15]":
                return "top-right of the inner part"
            elif bbox == "[0.58, 0.42, 0.15, 0.15]":
                return "bottom-left of the inner part"
            elif bbox == "[0.58, 0.58, 0.15, 0.15]":
                return "bottom-right of the inner part"

    def sample_and_extract_data(root_dir, metadata, num_samples=100):
        data = {}

        # List all the configuration folders
        config_folders = [f for f in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, f))]

        for config in config_folders:
            config_path = os.path.join(root_dir, config)
            all_files = [f for f in os.listdir(config_path) if f.endswith('.xml')]

            # Randomly sample num_samples files from each configuration folder
            sampled_files = all_files

            data[config] = []

            for file in sampled_files:
                file_path = os.path.join(config_path, file)

                # Parse the XML file
                tree = ET.parse(file_path)
                root = tree.getroot()

                # Extract information from XML
                example_data = {}
                panels = []
                for panel in root.findall('Panels/Panel'):
                    struct = panel.find('Struct')
                    struct_info = {
                        'name': struct.get('name'),
                        'components': []
                    }
                    entities = []
                    for component in struct.findall('Component'):
                        component_info = {
                            'id': component.get('id'),
                            'name': component.get('name'),
                            'layout': {}
                        }

                        layout = component.find('Layout')
                        if layout is not None:
                            layout_info = {
                                'name': layout.get('name'),
                                'number': layout.get('Number'),
                                'position': layout.get('Position'),
                                'uniformity': layout.get('Uniformity'),
                                'entities': []
                            }

                            for entity in layout.findall('Entity'):
                                assert int(entity.get('Type')) >= 1
                                entity_info = {
                                    'position': get_position(entity.get('bbox'), layout.get('name')),
                                    'shape': metadata['types']['Shape'][int(entity.get('Type'))-1],
                                    'size': metadata['types']['Size'][int(entity.get('Size'))],
                                    'color': metadata['types']['Color'][int(entity.get('Color'))]
                                }
                                entities.append(entity_info)
                                # layout_info['entities'].append(entity_info)

                            # component_info['layout'] = layout_info

                        # struct_info['components'].append(component_info)

                    panels.append(entities)
                example_data['panels'] = panels[:8]
                rules = []
                for rule_group in root.findall('Rules/Rule_Group'):
                    rule_group_info = {
                        'id': rule_group.get('id'),
                        'uniformity': rule_group.get('uniformity'),
                        'rules': []
                    }

                    for rule in rule_group.findall('Rule'):
                        rule_info = {
                            'name': rule.get('name'),
                            'attr': rule.get('attr'),
                            'value': rule.get('value')
                        }
                        rule_group_info['rules'].append(rule_info)

                    rules.append(rule_group_info)

                example_data['rules'] = rules
                example_data['filename'] = file
                # Store the extracted data
                data[config].append(example_data)

        return data

    sampled_data = sample_and_extract_data(args.RAVEN_src_file, metadata, args.images_per_configuration)


    # Read synonyms file
    with open(args.synonyms_json, 'r') as f:
        synonyms = json.load(f)

    template_matched_config = {"Direct_Answer_templates_normal": ["center_single", "distribute_four", "distribute_nine"],
                               "Direct_Answer_templates_LR": ["left_center_single_right_center_single"],
                               "Direct_Answer_templates_TD": ["up_center_single_down_center_single"],
                               "Direct_Answer_templates_in_out": ["in_center_single_out_center_single", "in_distribute_four_out_center_single"]}

    scene_count = 0
    for config in sampled_data:
        if config in template_matched_config[args.template_dir]:
            for i, instance in tqdm(enumerate(sampled_data[config])):
                questions = []
                filename = instance['filename']
                instance_struct = instance

                # if scene_count % args.reset_counts_every == 0:
                #     print('resetting counts')
                #     template_counts, template_answer_counts = reset_counts()
                scene_count += 1

                # Order templates by the number of questions we have so far for those
                # templates. This is a simple heuristic to give a flat distribution over
                # templates.
                templates_items = list(templates.items())
                # templates_items = sorted(templates_items, key=lambda x: template_counts[x[0][:2]])
                num_instantiated = 0
                for (fn, idx), template in templates_items:
                    if config == "center_single" and fn == "number.json":
                        continue
                    if args.verbose:
                        print('trying template ', fn, template)
                    ts, qs, ans, choices, param_values = instantiate_templates_dfs(
                        instance_struct,
                        template,
                        metadata,
                        synonyms,
                        config,
                        fn,
                        max_instances=args.instances_per_template,
                        verbose=False)

                    for t, q, a in zip(ts, qs, ans):
                        questions.append({
                            'filename': filename,
                            'question': t,
                            #'program': q,
                            'answer': a,
                            'template_filename': fn,
                            'choices': choices,
                            'config': config,
                            'image_filename': str(i) + "/" + select_filename(fn, param_values)
                        })

                    if len(ts) > 0:
                        if args.verbose:
                            print('got one!')
                        num_instantiated += 1
                        template_counts[(fn, idx)] += 1
                    elif args.verbose:
                        print('did not get any =(')
                    if num_instantiated >= args.templates_per_image:
                        break

                output_dir = args.output_dir+config
                if not os.path.exists(output_dir + '/' + str(i)):
                    os.makedirs(output_dir + '/' + str(i))
                new_output_dir = output_dir + '/' + str(i)
                with open(os.path.join(new_output_dir, "question.json"), 'w') as f:
                    npz_file = np.load(f"{args.RAVEN_src_file}/{config}/{filename.split('.')[0]}.npz")
                    save_image(npz_file, new_output_dir, i)
                    json.dump({
                        'question_num': len(questions),
                        'rules': instance_struct['rules'],
                        'panels': instance_struct['panels'],
                        'questions': questions,
                    }, f)


if __name__ == '__main__':
    args = parser.parse_args()
    main(args)

